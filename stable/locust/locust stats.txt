# Before start

Thu Oct 01 02:19 PM root@vpc-bijay-common-deployer-bijay-cd:~/locust-experiments/kubernetes(master)$ k top nodes; k top pod -n locust
NAME                          CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
ip-10-80-4-135.ec2.internal   93m          2%     450Mi           2%
ip-10-80-4-92.ec2.internal    168m         2%     1011Mi          3%
ip-10-80-5-190.ec2.internal   113m         1%     513Mi           1%
ip-10-80-5-65.ec2.internal    87m          2%     513Mi           3%
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-5c5f6d67bd-7jb22   3m           32Mi
locust-worker-585ffbd4b-9fp6n    1m           31Mi
locust-worker-585ffbd4b-h8fqc    1m           31Mi
locust-worker-585ffbd4b-nmbjp    1m           31Mi
locust-worker-585ffbd4b-q8tsk    1m           31Mi
locust-worker-585ffbd4b-tjdg4    1m           31Mi


# 









































1000u 100s 5w

927 uploads 16279 objects, 389.8 MB

1084 uploads 19512 objects, 467.3 MB

1072 uploads 19296 objects, 462.1 MB
1 failure -> "CatchResponseError('Log upload failed with code 504')"












































2 workers:
Current limits:
    cpu: 100m
    memory: 128Mi

kubectl top pod -n locust
Users - SpawnRate

Idle


10 - 1 [RPS 3.4]
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-845d67ddcd-d9c6s   2m           34Mi
locust-worker-65954b675b-jrwtq   1m           37Mi
locust-worker-65954b675b-nrdhz   1m           37Mi

100 - 5 [RPS 38.2]
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-845d67ddcd-d9c6s   3m           34Mi
locust-worker-65954b675b-jrwtq   50m          79Mi
locust-worker-65954b675b-nrdhz   48m          80Mi

X 1000 - 50 [RPS ] ---> Pod crashed
    1 worker pod restarted
    incorrect worker count in locust
    -> from above the pod is already at half its limit with [100 - 5].
    -> this test was 10x hence failed. max supported would have been 2x


2 workers
Default limits

1000 - 50 [RPS 390.5]
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-754ddbccb6-v7s7w   3m           32Mi
locust-worker-865659b668-c4mkt   458m         621Mi
locust-worker-865659b668-nqz4c   493m         651Mi

X after stopping test ---> Memory is not going down
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-754ddbccb6-v7s7w   2m           32Mi
locust-worker-865659b668-c4mkt   1m           620Mi
locust-worker-865659b668-nqz4c   1m           651Mi

5000 - 500 [RPS 600]
locust-master-754ddbccb6-v7s7w   4m           33Mi
locust-worker-865659b668-c4mkt   687m         2380Mi
locust-worker-865659b668-nqz4c   834m         2376Mi
x started seeing failure [api gw internal server error] ---> around 15%

X after stopping test ---> Memory is not going down
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-754ddbccb6-v7s7w   3m           33Mi
locust-worker-865659b668-c4mkt   1m           2380Mi
locust-worker-865659b668-nqz4c   1m           2350Mi




