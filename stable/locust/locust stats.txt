# Before start

Thu Oct 01 02:19 PM root@vpc-bijay-common-deployer-bijay-cd:~/locust-experiments/kubernetes(master)$ k top nodes; k top pod -n locust
NAME                          CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
ip-10-80-4-135.ec2.internal   93m          2%     450Mi           2%
ip-10-80-4-92.ec2.internal    168m         2%     1011Mi          3%
ip-10-80-5-190.ec2.internal   113m         1%     513Mi           1%
ip-10-80-5-65.ec2.internal    87m          2%     513Mi           3%
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-5c5f6d67bd-7jb22   3m           32Mi
locust-worker-585ffbd4b-9fp6n    1m           31Mi
locust-worker-585ffbd4b-h8fqc    1m           31Mi
locust-worker-585ffbd4b-nmbjp    1m           31Mi
locust-worker-585ffbd4b-q8tsk    1m           31Mi
locust-worker-585ffbd4b-tjdg4    1m           31Mi


# 500u 10s 5w [60, 61]
Thu Oct 01 02:28 PM root@vpc-bijay-common-deployer-bijay-cd:~/locust-experiments/kubernetes(master)$ k top nodes; k top pod -n locust
NAME                          CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
ip-10-80-4-135.ec2.internal   89m          2%     569Mi           3%
ip-10-80-4-92.ec2.internal    214m         2%     1100Mi          3%
ip-10-80-5-190.ec2.internal   129m         1%     689Mi           2%
ip-10-80-5-65.ec2.internal    94m          2%     603Mi           3%
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-5c5f6d67bd-7jb22   5m           32Mi
locust-worker-585ffbd4b-285rh    5m           113Mi
locust-worker-585ffbd4b-5btgs    5m           113Mi
locust-worker-585ffbd4b-vpt86    4m           112Mi
locust-worker-585ffbd4b-x9f85    4m           113Mi
locust-worker-585ffbd4b-xv78t    6m           113Mi

# 10Ku 50s 5w  [60, 61] ---> simulating ~50K
Thu Oct 01 02:46 PM root@vpc-bijay-common-deployer-bijay-cd:~/locust-experiments/kubernetes(master)$ k top nodes; k top pod -n locust
NAME                          CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
ip-10-80-4-135.ec2.internal   152m         3%     2109Mi          13%
ip-10-80-4-92.ec2.internal    292m         3%     2641Mi          8%
ip-10-80-5-190.ec2.internal   276m         3%     3779Mi          11%
ip-10-80-5-65.ec2.internal    167m         4%     2145Mi          13%
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-5c5f6d67bd-7jb22   5m           33Mi
locust-worker-585ffbd4b-285rh    82m          1659Mi
locust-worker-585ffbd4b-5btgs    73m          1659Mi
locust-worker-585ffbd4b-vpt86    71m          1659Mi
locust-worker-585ffbd4b-x9f85    67m          1659Mi
locust-worker-585ffbd4b-xv78t    81m          1659Mi









































1000u 100s 5w

927 uploads 16279 objects, 389.8 MB

1084 uploads 19512 objects, 467.3 MB

1072 uploads 19296 objects, 462.1 MB
1 failure -> "CatchResponseError('Log upload failed with code 504')"






1000 -> 500MB
50000 -> 25000MB





































2 workers:
Current limits:
    cpu: 100m
    memory: 128Mi

kubectl top pod -n locust
Users - SpawnRate

Idle


10 - 1 [RPS 3.4]
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-845d67ddcd-d9c6s   2m           34Mi
locust-worker-65954b675b-jrwtq   1m           37Mi
locust-worker-65954b675b-nrdhz   1m           37Mi

100 - 5 [RPS 38.2]
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-845d67ddcd-d9c6s   3m           34Mi
locust-worker-65954b675b-jrwtq   50m          79Mi
locust-worker-65954b675b-nrdhz   48m          80Mi

X 1000 - 50 [RPS ] ---> Pod crashed
    1 worker pod restarted
    incorrect worker count in locust
    -> from above the pod is already at half its limit with [100 - 5].
    -> this test was 10x hence failed. max supported would have been 2x


2 workers
Default limits

1000 - 50 [RPS 390.5]
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-754ddbccb6-v7s7w   3m           32Mi
locust-worker-865659b668-c4mkt   458m         621Mi
locust-worker-865659b668-nqz4c   493m         651Mi

X after stopping test ---> Memory is not going down
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-754ddbccb6-v7s7w   2m           32Mi
locust-worker-865659b668-c4mkt   1m           620Mi
locust-worker-865659b668-nqz4c   1m           651Mi

5000 - 500 [RPS 600]
locust-master-754ddbccb6-v7s7w   4m           33Mi
locust-worker-865659b668-c4mkt   687m         2380Mi
locust-worker-865659b668-nqz4c   834m         2376Mi
x started seeing failure [api gw internal server error] ---> around 15%

X after stopping test ---> Memory is not going down
NAME                             CPU(cores)   MEMORY(bytes)
locust-master-754ddbccb6-v7s7w   3m           33Mi
locust-worker-865659b668-c4mkt   1m           2380Mi
locust-worker-865659b668-nqz4c   1m           2350Mi




